{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KGCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTVIVGLGtcbfPUyMckzPCn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBXdQ5D9JvnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c346918-9715-49d5-b7a3-b663d39cef72"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html;\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html;\n",
        "!pip install -q torch-geometric;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.0 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 35.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYaSydifMDk_"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR,StepLR\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import sys\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from time import perf_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGEI4tInEDcp",
        "outputId": "1b95e91a-a1c6-40d6-c8b2-57b3b741e1d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "san7073Ieh0c"
      },
      "source": [
        "# Utils functions: visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8rEbaJtcJgp"
      },
      "source": [
        "def visualize(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    if torch.is_tensor(h):\n",
        "        h = h.detach().cpu().numpy()\n",
        "        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "        if epoch is not None and loss is not None:\n",
        "            plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    else:\n",
        "        nx.draw_networkx(h, pos=nx.spring_layout(h, seed=42), with_labels=False,\n",
        "                         node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "def normalize_adjacency_matrix(A, I):\n",
        "  \"\"\"\n",
        "  Creating a normalized adjacency matrix with self loops.\n",
        "  :param A: Sparse adjacency matrix.\n",
        "  :param I: Identity matrix.\n",
        "  :return A_tile_hat: Normalized adjacency matrix.\"\"\"\n",
        "  \n",
        "  A_tilde = I\n",
        "  degrees = A_tilde.sum(axis=0)[0].tolist()\n",
        "  D = sp.diags(degrees, [0])\n",
        "  D = D.power(-0.5)\n",
        "  A_tilde_hat = D.dot(A_tilde).dot(D)\n",
        "  return A_tilde_hat\n",
        "\n",
        "def normalize(mx):\n",
        "  \"\"\"Row-normalize sparse matrix ---> Node features\"\"\"\n",
        "  rowsum = np.array(mx.sum(1))\n",
        "  r_inv = np.power(rowsum, -1).flatten()\n",
        "  r_inv[np.isinf(r_inv)] = 0.\n",
        "  r_mat_inv = sp.diags(r_inv)\n",
        "  mx = r_mat_inv.dot(mx)\n",
        "  return mx\n",
        "\n",
        "def normalizemx(mx):\n",
        "  \"\"\"Normalization for Scattering GCN\"\"\"\n",
        "  degrees = mx.sum(axis=0)[0].tolist()\n",
        "  #    print(degrees)\n",
        "  D = sp.diags(degrees, [0])\n",
        "  D = D.power(-1)\n",
        "  mx = mx.dot(D)\n",
        "  return mx\n",
        "\n",
        "\n",
        "def scattering1st(spmx,order):\n",
        "\n",
        "  I_n = sp.eye(spmx.shape[0])\n",
        "  adj_sct = 0.5*(spmx+I_n) # P = 1/2 * (I + WD^-1)\n",
        "  adj_power = adj_sct\n",
        "  adj_power = sparse_mx_to_torch_sparse_tensor(adj_power).cuda()\n",
        "  adj_sct = sparse_mx_to_torch_sparse_tensor(adj_sct).cuda()\n",
        "  I_n = sparse_mx_to_torch_sparse_tensor(I_n)\n",
        "  if order>1:\n",
        "    for i in range(order-1):\n",
        "      # Generating P^(2^(k-1))\n",
        "      adj_power = torch.spmm(adj_power,adj_sct.to_dense())\n",
        "      print('Generating SCT')\n",
        "    # Generating. final scattering of order K -> (I - P^(2^(k-1))) * P^(2^(k-1))\n",
        "    adj_int = torch.spmm((adj_power-I_n.cuda()),adj_power)\n",
        "  else:\n",
        "    # Generating. final scattering of order K -> (I - P^(2^(k-1))) * P^(2^(k-1))\n",
        "    adj_int = torch.spmm((adj_power-I_n.cuda()),adj_power.to_dense())\n",
        "  return adj_int\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "  \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "  sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "  indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "  values = torch.from_numpy(sparse_mx.data)\n",
        "  shape = torch.Size(sparse_mx.shape)\n",
        "  return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "def parse_index_file(filename):\n",
        "  #Parse index file.\n",
        "  index = []\n",
        "  for line in open(filename):\n",
        "      index.append(int(line.strip()))\n",
        "  return index\n",
        "\n",
        "def accuracy(output, labels):\n",
        "  preds = output.max(1)[1].type_as(labels)\n",
        "  correct = preds.eq(labels).double()\n",
        "  correct = correct.sum()\n",
        "  return correct / len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21wp5VSYesK0"
      },
      "source": [
        "# Preprocessing: Importing datasets\n",
        "\n",
        "Importing the datasets, split into training, validation and testing, normalizing it, getting the adjacency matrix, the scattering matrices, features matrix, index of nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBWtKSG0MNi5"
      },
      "source": [
        "def load_citation(dataset_str=\"citeseer\", normalization=\"AugNormAdj\", cuda=True):\n",
        "  \"\"\"  \n",
        "  Load Citation Networks Datasets.\n",
        "  \"\"\"\n",
        "  names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "  objects = []\n",
        "  for i in range(len(names)):\n",
        "    with open(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n",
        "      if sys.version_info > (3, 0):\n",
        "          objects.append(pkl.load(f, encoding='latin1'))\n",
        "      else:\n",
        "          objects.append(pkl.load(f))\n",
        "\n",
        "  x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "  test_idx_reorder = parse_index_file(\"/content/drive/MyDrive/THESIS/Databases/data/ind.{}.test.index\".format(dataset_str))\n",
        "  test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "  if dataset_str == 'citeseer':\n",
        "    # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "    # Find isolated nodes, add them as zero-vecs into the right position\n",
        "    test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "    tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "    tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "    tx = tx_extended\n",
        "    ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
        "    ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
        "    ty = ty_extended\n",
        "\n",
        "  features = sp.vstack((allx, tx)).tolil()\n",
        "  features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "  adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "  labels = np.vstack((ally, ty))\n",
        "  labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
        "\n",
        "\n",
        "  idx_test = test_idx_range.tolist()\n",
        "  idx_train = range(len(y))\n",
        "  idx_val = range(len(y), len(y)+500)\n",
        "\n",
        "  #   take from https://github.com/tkipf/pygcn/blob/master/pygcn/utils.py\n",
        "  #    idx_train = range(140)\n",
        "  #    idx_val = range(200, 500)\n",
        "  #    idx_test = range(500, 1500)\n",
        "\n",
        "\n",
        "  labels = torch.LongTensor(labels)\n",
        "  labels = torch.max(labels, dim=1)[1]\n",
        "  idx_train = torch.LongTensor(idx_train)\n",
        "  idx_val = torch.LongTensor(idx_val)\n",
        "  idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "  features = normalize(features)\n",
        "  A_tilde = normalize_adjacency_matrix(adj,sp.eye(adj.shape[0]))\n",
        "  adj = normalizemx(adj)\n",
        "  features = torch.FloatTensor(np.array(features.todense()))\n",
        "  print('Loading')\n",
        "  #adj_sct1 = scattering1st(adj,1) ## psi_1 = P(I-P)\n",
        "  #adj_sct2 = scattering1st(adj,2) # psi_2 = P^2(I-P^2)\n",
        "  #adj_sct4 = scattering1st(adj,4) # psi_3 = P^4(I-P^4)\n",
        "  adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "  A_tilde = sparse_mx_to_torch_sparse_tensor(A_tilde)\n",
        "  return adj,A_tilde,features, labels, idx_train, idx_val, idx_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJmG5IVVEiZ6",
        "outputId": "52b047cc-4955-4ef8-aad1-cbde965f2283"
      },
      "source": [
        "adj,A_tilde,features, labels, idx_train, idx_val, idx_test = load_citation()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in power\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws9SJpLPlpXa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS7t580peyK8"
      },
      "source": [
        "# MODELS\n",
        "\n",
        "First the convolutional structure is defined to finally being called in a nn Module. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAabB4Oy0u9W"
      },
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "         \n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvI__GAEMvlS",
        "outputId": "a14b7c11-6789-47bd-8981-79447263b686"
      },
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self,nfeat,n_class, hidden_channels, degree):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.conv1 = GraphConvolution(nfeat, hidden_channels)\n",
        "        self.lin1 = nn.Linear(hidden_channels,n_class)\n",
        "        self.d = degree\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.conv1(x, adj)\n",
        "        x = x.relu()\n",
        "        for i in range(self.d):\n",
        "          x = torch.spmm(adj, x)\n",
        "        return self.lin1(x)\n",
        "\n",
        "model = GCN(features.shape[1],labels.max().item() + 1, hidden_channels=16, degree=2)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GraphConvolution (3703 -> 16)\n",
            "  (lin1): Linear(in_features=16, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_brRGa0pe40k"
      },
      "source": [
        "# Execution of the overall model\n",
        "\n",
        "Hyperparameter definition, model instatiated, and training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzm8QWtOM7cH"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 200\n",
        "lr = 0.01\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "    features = features.cuda()\n",
        "    A_tilde = A_tilde.cuda()\n",
        "    adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = StepLR(optimizer, step_size=50, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DgD1SpIcNhUT",
        "outputId": "2ca808c4-cbb9-4251-9ef5-d0b467af1c3b"
      },
      "source": [
        "import time\n",
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})'''))\n",
        "\n",
        "def acc1(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def train(x, adj, labels, idx_train):\n",
        "  t = perf_counter()\n",
        "  optimizer.zero_grad()\n",
        "  out = model(x, adj)\n",
        "  loss = criterion(out[idx_train], labels[idx_train])  # Compute the loss solely based on the training nodes.\n",
        "  train_acc = acc1(out[idx_train], labels[idx_train])\n",
        "  loss.backward()  # Derive gradients.\n",
        "  optimizer.step()\n",
        "  train_time = perf_counter()-t\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    corrects = 0\n",
        "    output = model(x, adj)\n",
        "    val_acc = acc1(out[idx_val], labels[idx_val])\n",
        "  return val_acc, train_time\n",
        "\n",
        "def test(nfeat, adj, labels, idx_test):\n",
        "  model.eval()\n",
        "  out = F.softmax(model(nfeat, adj), dim=1)\n",
        "  test_acc =  acc1(out[idx_test], labels[idx_test])\n",
        "  return test_acc\n",
        "\n",
        "global_acc = []\n",
        "for i in range(5):\n",
        "  acc_list = []\n",
        "  loss_list = []\n",
        "  for epoch in range(200):\n",
        "    loss, h= train(features, A_tilde, labels, idx_train)\n",
        "    accuracy = test(features, A_tilde, labels, idx_test)\n",
        "    acc_list.append(accuracy)\n",
        "    loss_list.append(loss)\n",
        "  total_acc = accuracy\n",
        "  global_acc.append(total_acc.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 430})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwI0i7xoNl4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4708a1b8-7ef4-495c-f7b8-cef119987222"
      },
      "source": [
        "import numpy as np\n",
        "print(global_acc)\n",
        "accuracy = np.mean(global_acc)\n",
        "print('Acc after 5 runs:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5, 0.503, 0.493, 0.492, 0.492]\n",
            "Acc after 5 runs: 0.496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRwtS5K5_aBr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}